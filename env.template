# Gemini API Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# Optional: OpenAI API Key (if using OpenAI models as fallback)
# OPENAI_API_KEY=your_openai_api_key_here

# Optional: GPT url if using different openAI enabled endpoint
# GPT_ENDPOINT="http://192.168.1.27:1234/v1"

# Optional: Model Id used to select model from endpoint
# MODEL_ID="qwen/qwen3-4b-2507"

# LLM Model Configuration
# Default model to use for calculations
# MODEL_NAME="gemini-2.5-flash"

# Phoenix Telemetry Configuration
# Set to 'true' to enable Phoenix telemetry for monitoring LLM calls
PHOENIX_ENABLED=false
# Phoenix endpoint (default: http://localhost:6006)
# PHOENIX_ENDPOINT="http://localhost:6006"
# Phoenix project name for organizing traces
# PHOENIX_PROJECT_NAME="calculator-agent"

# Output Configuration
# Default output directory for agent results
# OUTPUT_DIR="./results"
# Enable verbose logging
# VERBOSE_LOGGING=false

# RAG Configuration
# Enable/disable RAG functionality (set to 'true' to enable retrieval)
RAG_ENABLED=false
# Embedding model for vector search (local model)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Chroma vector database directory
CHROMA_DIR=./chroma_db